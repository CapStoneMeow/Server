from fastapi import HTTPException
from transformers import AutoModelForSequenceClassification, AutoConfig
import torch
import os
from tokenization_kobert import KoBertTokenizer

MODEL_DIR = "./model/kobert"

label_map = {
    0: "ì´ˆë“±_ì €í•™ë…„",
    1: "ì´ˆë“±_ê³ í•™ë…„",
    2: "ì´ˆë“±_ì¤‘í•™ë…„"
}

_tokenizer = None
_model = None

def load_model():
    global _tokenizer, _model
    if _tokenizer is None or _model is None:
        try:
            print("ğŸ“¦ KoBERT .bin ëª¨ë¸ ë¡œë“œ ì¤‘...")
            print("ğŸ“‚ MODEL_DIR ë‚´ìš©:", os.listdir(MODEL_DIR))

            # âœ… KoBertTokenizerëŠ” custom ì´ˆê¸°í™” (from_pretrained X)
            vocab_file = os.path.join(MODEL_DIR, "tokenizer_78b3253a26.model")
            vocab_txt = os.path.join(MODEL_DIR, "vocab.txt")
            _tokenizer = KoBertTokenizer(vocab_file=vocab_file, vocab_txt=vocab_txt)

            # âœ… config ê°•ì œ ì„¸íŒ… (num_labels=3)
            config = AutoConfig.from_pretrained(MODEL_DIR)
            config.num_labels = 3

            # âœ… ëª¨ë¸ ë¡œë“œ
            _model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR, config=config, local_files_only=True)
            _model.eval()

            print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:", e)
            raise RuntimeError("ëª¨ë¸ ë˜ëŠ” í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹¤íŒ¨")

def predict_grade(text: str) -> dict:
    try:
        load_model()
        inputs = _tokenizer(text, return_tensors="pt", padding="max_length", truncation=True, max_length=128)
        with torch.no_grad():
            outputs = _model(**inputs)
            pred = torch.argmax(outputs.logits, dim=1).item()

        return {
            "label_index": pred,
            "label": label_map.get(pred, "Unknown")
        }

    except Exception as e:
        print("âŒ ì˜ˆì¸¡ ì‹¤íŒ¨:", e)
        raise HTTPException(status_code=500, detail=f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
