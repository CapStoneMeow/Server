import torch
from transformers import BertTokenizer, BertForSequenceClassification
import os

MODEL_PATH = "./model/kobert"

label_map = {
    0: "ì´ˆë“±_ì €í•™ë…„",
    1: "ì´ˆë“±_ê³ í•™ë…„"
}

_tokenizer = None
_model = None

def load_model():
    global _tokenizer, _model
    if _tokenizer is None or _model is None:
        try:
            print("ðŸ“¦ KoBERT ëª¨ë¸ ë¡œë“œ ì¤‘...")
            print("ðŸ“‚ MODEL_PATH ë‚´ìš©:", os.listdir(MODEL_PATH))

            _tokenizer = BertTokenizer.from_pretrained(
                MODEL_PATH,
                local_files_only=True
            )

            _model = BertForSequenceClassification.from_pretrained(
                MODEL_PATH,
                local_files_only=True
            )
            _model.eval()
            print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:", e)
            raise RuntimeError("ëª¨ë¸ ë˜ëŠ” í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

def predict_grade(text: str) -> dict:
    load_model()

    inputs = _tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding="max_length",
        max_length=128
    )

    with torch.no_grad():
        outputs = _model(**inputs)
        pred = torch.argmax(outputs.logits, dim=1).item()

    return {
        "label_index": pred,
        "label": label_map.get(pred, "Unknown")
    }
